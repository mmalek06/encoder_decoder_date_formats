{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from datetime import datetime, timedelta\n",
    "from typing import Callable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "POSSIBLE_INPUT_CHARS = f'{\"\".join(list(map(str, range(10))))}{string.ascii_lowercase}-'\n",
    "POSSIBLE_OUTPUT_CHARS = f'{\"\".join(list(map(str, range(10))))}-'\n",
    "CURRENT_DAY = datetime.utcnow()\n",
    "ROW_COUNT = 14000\n",
    "\n",
    "\n",
    "def string_to_ids(s: str, chars: str) -> list[int]:\n",
    "    ids = []\n",
    "\n",
    "    for char in s.lower():\n",
    "        idx = chars.index(char)\n",
    "\n",
    "        ids.append(idx)\n",
    "\n",
    "    return ids\n",
    "\n",
    "\n",
    "def shuffle(vals: tf.RaggedTensor, targets: tf.RaggedTensor) -> (tf.RaggedTensor, tf.RaggedTensor):\n",
    "    a = tf.random.shuffle(tf.range(vals.shape[0]))\n",
    "    b = tf.reshape(a, (vals.shape[0], 1))\n",
    "    shuffled_vals = tf.gather_nd(vals, b)\n",
    "    shuffled_targets = tf.gather_nd(targets, b)\n",
    "\n",
    "    return shuffled_vals, shuffled_targets\n",
    "\n",
    "\n",
    "def pad_year(year: int) -> str:\n",
    "    return f'{\"\".join(map(str, [0] * (4 - len(str(year)))))}{year}'\n",
    "\n",
    "\n",
    "def get_date_pairs() -> (np.ndarray, np.ndarray):\n",
    "    xs = []\n",
    "    ys = []\n",
    "    all_years = np.arange(ROW_COUNT).tolist()\n",
    "    years_padded = np.array([pad_year(year) for year in all_years])\n",
    "\n",
    "    np.random.shuffle(years_padded)\n",
    "\n",
    "    for counter in range(ROW_COUNT):\n",
    "        date = CURRENT_DAY - timedelta(days=counter)\n",
    "        year_month_day = date.strftime('%Y-%m-%d')\n",
    "        year_month_name_day = date.strftime('%Y-%B-%d')\n",
    "        _, month_name, day = year_month_name_day.split('-')\n",
    "        year = years_padded[counter]\n",
    "        year_month_day = f'{year}-{year_month_day[5:]}'\n",
    "        xs.append(tf.constant(\n",
    "            string_to_ids(f'{year}-', POSSIBLE_INPUT_CHARS) +\n",
    "            string_to_ids(f'{month_name}-', POSSIBLE_INPUT_CHARS) +\n",
    "            string_to_ids(day, POSSIBLE_INPUT_CHARS)))\n",
    "        ys.append(tf.constant(string_to_ids(year_month_day, POSSIBLE_OUTPUT_CHARS)))\n",
    "\n",
    "    ragged_xs = tf.ragged.stack(xs, axis=0)\n",
    "    ragged_ys = tf.ragged.stack(ys, axis=0)\n",
    "\n",
    "    return shuffle(ragged_xs, ragged_ys)\n",
    "\n",
    "\n",
    "X, y = get_date_pairs()\n",
    "X = (X + 1).to_tensor()\n",
    "y = y.to_tensor()\n",
    "seventy_percent_count = int(X.shape[0] * .7)\n",
    "ninety_percent_count = int(X.shape[0] * .9)\n",
    "X_train, y_train = X[:seventy_percent_count, :], y[:seventy_percent_count, :]\n",
    "X_valid, y_valid = X[seventy_percent_count:ninety_percent_count, :], y[seventy_percent_count:ninety_percent_count, :]\n",
    "X_test, y_test = X[ninety_percent_count:, :], y[ninety_percent_count:, :]\n",
    "max_output_length = y.shape[1]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "sos_id = len(POSSIBLE_OUTPUT_CHARS) + 1\n",
    "\n",
    "\n",
    "def shifted_output_sequences(y: tf.Tensor) -> tf.Tensor:\n",
    "    sos_tokens = tf.fill(dims=(len(y), 1), value=sos_id)\n",
    "\n",
    "    return tf.concat([sos_tokens, y[:, :-1]], axis=1)\n",
    "\n",
    "\n",
    "X_train_decoder = shifted_output_sequences(y_train)\n",
    "X_valid_decoder = shifted_output_sequences(y_valid)\n",
    "X_test_decoder = shifted_output_sequences(y_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training part"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def scheduler(drop_after: int) -> Callable[[int, int], float]:\n",
    "    def drop(epoch: int, learning_rate: int) -> float:\n",
    "        if epoch < drop_after:\n",
    "            return learning_rate\n",
    "        else:\n",
    "            return learning_rate * tf.math.exp(-0.2)\n",
    "\n",
    "    return drop\n",
    "\n",
    "\n",
    "def get_callbacks() -> (keras.callbacks.EarlyStopping, keras.callbacks.ModelCheckpoint, keras.callbacks.TensorBoard):\n",
    "    the_name = 'encoder_decoder_w_teacher_forcing'\n",
    "    patience = 5\n",
    "    model_dir = os.path.join(os.curdir, 'saved_models')\n",
    "    run_logdir_root = os.path.join(os.curdir, 'tensor_logs')\n",
    "    dirs = [\n",
    "        name\n",
    "        for name in os.listdir(run_logdir_root)\n",
    "        if os.path.isdir(os.path.join(run_logdir_root, name)) and name.startswith(name)\n",
    "    ]\n",
    "    dirs_count = len(dirs) + 1\n",
    "    run_logdir = os.path.join(run_logdir_root, f'{the_name}_{dirs_count}')\n",
    "    early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=patience, min_delta=1e-4)\n",
    "    model_checkpoint = keras.callbacks.ModelCheckpoint(os.path.join(model_dir, f'{the_name}_{dirs_count}.h5'), save_best_only=True)\n",
    "    tensorboard = keras.callbacks.TensorBoard(run_logdir, histogram_freq=1, profile_batch=10)\n",
    "    lr_scheduler = keras.callbacks.LearningRateScheduler(scheduler(9))\n",
    "\n",
    "    return early_stopping, model_checkpoint, tensorboard, lr_scheduler"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def get_model() -> keras.Model:\n",
    "    embedding_size = 32\n",
    "    encoder_input = keras.Input(shape=(None,))\n",
    "    encoder_embedding = keras.layers.Embedding(input_dim=len(POSSIBLE_INPUT_CHARS) + 1,\n",
    "                                               output_dim=embedding_size)(encoder_input)\n",
    "    encoder_lstm = keras.layers.LSTM(128, return_state=True)\n",
    "    _, encoder_state_h, encoder_state_c = encoder_lstm(encoder_embedding)\n",
    "    encoder_states = [encoder_state_h, encoder_state_c]\n",
    "\n",
    "    decoder_input = keras.Input(shape=(None,))\n",
    "    decoder_embedding = keras.layers.Embedding(input_dim=len(POSSIBLE_OUTPUT_CHARS) + 2,\n",
    "                                               output_dim=embedding_size)(decoder_input)\n",
    "    decoder_lstm = keras.layers.LSTM(128, return_sequences=True)\n",
    "    decoder_lstm_output = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n",
    "    decoder_dense = keras.layers.Dense(len(POSSIBLE_OUTPUT_CHARS) + 1, activation='softmax')\n",
    "    decoder_outputs = decoder_dense(decoder_lstm_output)\n",
    "    model = keras.Model(inputs=[encoder_input, decoder_input], outputs=[decoder_outputs])\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "307/307 [==============================] - 7s 15ms/step - loss: 1.3228 - accuracy: 0.4972 - val_loss: 0.9742 - val_accuracy: 0.6169 - lr: 0.0100\n",
      "Epoch 2/40\n",
      "307/307 [==============================] - 4s 12ms/step - loss: 0.6536 - accuracy: 0.7293 - val_loss: 0.3421 - val_accuracy: 0.8598 - lr: 0.0100\n",
      "Epoch 3/40\n",
      "307/307 [==============================] - 4s 12ms/step - loss: 0.1432 - accuracy: 0.9527 - val_loss: 0.0471 - val_accuracy: 0.9881 - lr: 0.0100\n",
      "Epoch 4/40\n",
      "307/307 [==============================] - 4s 12ms/step - loss: 0.0219 - accuracy: 0.9952 - val_loss: 0.0153 - val_accuracy: 0.9966 - lr: 0.0100\n",
      "Epoch 5/40\n",
      "307/307 [==============================] - 4s 12ms/step - loss: 0.0157 - accuracy: 0.9967 - val_loss: 0.0133 - val_accuracy: 0.9964 - lr: 0.0100\n",
      "Epoch 6/40\n",
      "307/307 [==============================] - 4s 12ms/step - loss: 0.0094 - accuracy: 0.9978 - val_loss: 0.0210 - val_accuracy: 0.9935 - lr: 0.0100\n",
      "Epoch 7/40\n",
      "307/307 [==============================] - 4s 12ms/step - loss: 0.0118 - accuracy: 0.9970 - val_loss: 0.0030 - val_accuracy: 0.9995 - lr: 0.0100\n",
      "Epoch 8/40\n",
      "307/307 [==============================] - 4s 12ms/step - loss: 0.0016 - accuracy: 0.9998 - val_loss: 0.0095 - val_accuracy: 0.9970 - lr: 0.0100\n",
      "Epoch 9/40\n",
      "307/307 [==============================] - 4s 12ms/step - loss: 0.0153 - accuracy: 0.9957 - val_loss: 0.0036 - val_accuracy: 0.9996 - lr: 0.0100\n",
      "Epoch 10/40\n",
      "307/307 [==============================] - 4s 12ms/step - loss: 0.0012 - accuracy: 0.9999 - val_loss: 7.8671e-04 - val_accuracy: 1.0000 - lr: 0.0082\n",
      "Epoch 11/40\n",
      "307/307 [==============================] - 4s 12ms/step - loss: 3.8129e-04 - accuracy: 1.0000 - val_loss: 3.6044e-04 - val_accuracy: 1.0000 - lr: 0.0067\n",
      "Epoch 12/40\n",
      "307/307 [==============================] - 4s 12ms/step - loss: 2.2917e-04 - accuracy: 1.0000 - val_loss: 2.7385e-04 - val_accuracy: 1.0000 - lr: 0.0055\n",
      "Epoch 13/40\n",
      "307/307 [==============================] - 4s 12ms/step - loss: 1.8018e-04 - accuracy: 1.0000 - val_loss: 2.2960e-04 - val_accuracy: 1.0000 - lr: 0.0045\n",
      "Epoch 14/40\n",
      "307/307 [==============================] - 4s 12ms/step - loss: 1.5175e-04 - accuracy: 1.0000 - val_loss: 2.0091e-04 - val_accuracy: 1.0000 - lr: 0.0037\n",
      "Epoch 15/40\n",
      "307/307 [==============================] - 4s 12ms/step - loss: 1.3227e-04 - accuracy: 1.0000 - val_loss: 1.7981e-04 - val_accuracy: 1.0000 - lr: 0.0030\n",
      "Epoch 16/40\n",
      "307/307 [==============================] - 4s 12ms/step - loss: 1.1832e-04 - accuracy: 1.0000 - val_loss: 1.6428e-04 - val_accuracy: 1.0000 - lr: 0.0025\n",
      "Epoch 17/40\n",
      "307/307 [==============================] - 4s 12ms/step - loss: 1.0777e-04 - accuracy: 1.0000 - val_loss: 1.5182e-04 - val_accuracy: 1.0000 - lr: 0.0020\n",
      "Epoch 18/40\n",
      "307/307 [==============================] - 4s 12ms/step - loss: 9.9353e-05 - accuracy: 1.0000 - val_loss: 1.4225e-04 - val_accuracy: 1.0000 - lr: 0.0017\n"
     ]
    }
   ],
   "source": [
    "model = get_model()\n",
    "adam_opt = keras.optimizers.Adam(learning_rate=.01)\n",
    "\n",
    "model.compile(optimizer=adam_opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "early_stopping, model_checkpoint, tensorboard, lr_scheduler = get_callbacks()\n",
    "history = model.fit(\n",
    "    [X_train, X_train_decoder],\n",
    "    y_train,\n",
    "    epochs=40,\n",
    "    validation_data=([X_valid, X_valid_decoder], y_valid),\n",
    "    callbacks=[early_stopping, model_checkpoint, tensorboard, lr_scheduler])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
