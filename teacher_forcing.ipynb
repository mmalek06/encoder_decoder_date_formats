{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from datetime import datetime, timedelta\n",
    "from typing import Callable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "POSSIBLE_INPUT_CHARS = f'{\"\".join(list(map(str, range(10))))}{string.ascii_lowercase}-'\n",
    "POSSIBLE_OUTPUT_CHARS = f'{\"\".join(list(map(str, range(10))))}-'\n",
    "CURRENT_DAY = datetime.utcnow()\n",
    "ROW_COUNT = 14000\n",
    "\n",
    "\n",
    "def string_to_ids(s: str, chars: str) -> list[int]:\n",
    "    ids = []\n",
    "\n",
    "    for char in s.lower():\n",
    "        idx = chars.index(char)\n",
    "\n",
    "        ids.append(idx)\n",
    "\n",
    "    return ids\n",
    "\n",
    "\n",
    "def shuffle(vals: tf.RaggedTensor, targets: tf.RaggedTensor) -> (tf.RaggedTensor, tf.RaggedTensor):\n",
    "    a = tf.random.shuffle(tf.range(vals.shape[0]))\n",
    "    b = tf.reshape(a, (vals.shape[0], 1))\n",
    "    shuffled_vals = tf.gather_nd(vals, b)\n",
    "    shuffled_targets = tf.gather_nd(targets, b)\n",
    "\n",
    "    return shuffled_vals, shuffled_targets\n",
    "\n",
    "\n",
    "def pad_year(year: int) -> str:\n",
    "    return f'{\"\".join(map(str, [0] * (4 - len(str(year)))))}{year}'\n",
    "\n",
    "\n",
    "def get_date_pairs() -> (np.ndarray, np.ndarray):\n",
    "    xs = []\n",
    "    ys = []\n",
    "    all_years = np.arange(ROW_COUNT).tolist()\n",
    "    years_padded = np.array([pad_year(year) for year in all_years])\n",
    "\n",
    "    np.random.shuffle(years_padded)\n",
    "\n",
    "    for counter in range(ROW_COUNT):\n",
    "        date = CURRENT_DAY - timedelta(days=counter)\n",
    "        year_month_day = date.strftime('%Y-%m-%d')\n",
    "        year_month_name_day = date.strftime('%Y-%B-%d')\n",
    "        _, month_name, day = year_month_name_day.split('-')\n",
    "        year = years_padded[counter]\n",
    "        year_month_day = f'{year}-{year_month_day[5:]}'\n",
    "        xs.append(tf.constant(\n",
    "            string_to_ids(f'{year}-', POSSIBLE_INPUT_CHARS) +\n",
    "            string_to_ids(f'{month_name}-', POSSIBLE_INPUT_CHARS) +\n",
    "            string_to_ids(day, POSSIBLE_INPUT_CHARS)))\n",
    "        ys.append(tf.constant(string_to_ids(year_month_day, POSSIBLE_OUTPUT_CHARS)))\n",
    "\n",
    "    ragged_xs = tf.ragged.stack(xs, axis=0)\n",
    "    ragged_ys = tf.ragged.stack(ys, axis=0)\n",
    "\n",
    "    return shuffle(ragged_xs, ragged_ys)\n",
    "\n",
    "\n",
    "X, y = get_date_pairs()\n",
    "X = (X + 1).to_tensor()\n",
    "y = y.to_tensor()\n",
    "seventy_percent_count = int(X.shape[0] * .7)\n",
    "ninety_percent_count = int(X.shape[0] * .9)\n",
    "X_train, y_train = X[:seventy_percent_count, :], y[:seventy_percent_count, :]\n",
    "X_valid, y_valid = X[seventy_percent_count:ninety_percent_count, :], y[seventy_percent_count:ninety_percent_count, :]\n",
    "X_test, y_test = X[ninety_percent_count:, :], y[ninety_percent_count:, :]\n",
    "max_output_length = y.shape[1]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "sos_id = len(POSSIBLE_OUTPUT_CHARS) + 1\n",
    "\n",
    "\n",
    "def shifted_output_sequences(y: tf.Tensor) -> tf.Tensor:\n",
    "    sos_tokens = tf.fill(dims=(len(y), 1), value=sos_id)\n",
    "\n",
    "    return tf.concat([sos_tokens, y[:, :-1]], axis=1)\n",
    "\n",
    "\n",
    "X_train_decoder = shifted_output_sequences(y_train)\n",
    "X_valid_decoder = shifted_output_sequences(y_valid)\n",
    "X_test_decoder = shifted_output_sequences(y_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "def get_callbacks() -> (keras.callbacks.EarlyStopping, keras.callbacks.ModelCheckpoint, keras.callbacks.TensorBoard):\n",
    "    the_name = 'encoder_decoder_w_teacher_forcing'\n",
    "    patience = 5\n",
    "    model_dir = os.path.join(os.curdir, 'saved_models')\n",
    "    run_logdir_root = os.path.join(os.curdir, 'tensor_logs')\n",
    "    dirs = [\n",
    "        name\n",
    "        for name in os.listdir(run_logdir_root)\n",
    "        if os.path.isdir(os.path.join(run_logdir_root, name)) and name.startswith(name)\n",
    "    ]\n",
    "    dirs_count = len(dirs) + 1\n",
    "    run_logdir = os.path.join(run_logdir_root, f'{the_name}_{dirs_count}')\n",
    "    early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=patience)\n",
    "    model_checkpoint = keras.callbacks.ModelCheckpoint(os.path.join(model_dir, f'{the_name}_{dirs_count}.h5'), save_best_only=True)\n",
    "    tensorboard = keras.callbacks.TensorBoard(run_logdir, histogram_freq=1, profile_batch=10)\n",
    "\n",
    "    return early_stopping, model_checkpoint, tensorboard"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "def scheduler(drop_after: int) -> Callable[[int, int], float]:\n",
    "    def drop(epoch: int, learning_rate: int) -> float:\n",
    "        if epoch < drop_after:\n",
    "            return learning_rate\n",
    "        else:\n",
    "            return learning_rate * tf.math.exp(-0.1)\n",
    "\n",
    "    return drop\n",
    "\n",
    "\n",
    "def get_model() -> keras.Model:\n",
    "    embedding_size = 32\n",
    "    encoder_input = keras.Input(shape=(None,))\n",
    "    encoder_embedding = keras.layers.Embedding(input_dim=len(POSSIBLE_INPUT_CHARS) + 1,\n",
    "                                               output_dim=embedding_size)(encoder_input)\n",
    "    encoder_lstm = keras.layers.LSTM(128, return_state=True)\n",
    "    _, encoder_state_h, encoder_state_c = encoder_lstm(encoder_embedding)\n",
    "    encoder_states = [encoder_state_h, encoder_state_c]\n",
    "\n",
    "    decoder_input = keras.Input(shape=(None,))\n",
    "    decoder_embedding = keras.layers.Embedding(input_dim=len(POSSIBLE_OUTPUT_CHARS) + 2,\n",
    "                                               output_dim=embedding_size)(decoder_input)\n",
    "    decoder_lstm = keras.layers.LSTM(128, return_sequences=True)\n",
    "    decoder_lstm_output = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n",
    "    decoder_dense = keras.layers.Dense(len(POSSIBLE_OUTPUT_CHARS) + 1, activation='softmax')\n",
    "    decoder_outputs = decoder_dense(decoder_lstm_output)\n",
    "    model = keras.Model(inputs=[encoder_input, decoder_input], outputs=[decoder_outputs])\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "307/307 [==============================] - 8s 16ms/step - loss: 1.6633 - accuracy: 0.3945 - val_loss: 1.4610 - val_accuracy: 0.4366 - lr: 0.1000\n",
      "Epoch 2/40\n",
      "307/307 [==============================] - 4s 13ms/step - loss: 1.4694 - accuracy: 0.4314 - val_loss: 1.4594 - val_accuracy: 0.4362 - lr: 0.1000\n",
      "Epoch 3/40\n",
      "307/307 [==============================] - 4s 13ms/step - loss: 1.4517 - accuracy: 0.4320 - val_loss: 1.4453 - val_accuracy: 0.4347 - lr: 0.1000\n",
      "Epoch 4/40\n",
      "307/307 [==============================] - 4s 12ms/step - loss: 1.4519 - accuracy: 0.4327 - val_loss: 1.4420 - val_accuracy: 0.4295 - lr: 0.1000\n",
      "Epoch 5/40\n",
      "307/307 [==============================] - 4s 12ms/step - loss: 1.5796 - accuracy: 0.4198 - val_loss: 1.5287 - val_accuracy: 0.4284 - lr: 0.1000\n",
      "Epoch 6/40\n",
      "307/307 [==============================] - 4s 13ms/step - loss: 1.5562 - accuracy: 0.4189 - val_loss: 1.5593 - val_accuracy: 0.4006 - lr: 0.0905\n",
      "Epoch 7/40\n",
      "307/307 [==============================] - 4s 12ms/step - loss: 1.6024 - accuracy: 0.4026 - val_loss: 1.6939 - val_accuracy: 0.3836 - lr: 0.0819\n",
      "Epoch 8/40\n",
      "307/307 [==============================] - 4s 12ms/step - loss: 1.6251 - accuracy: 0.3931 - val_loss: 1.6100 - val_accuracy: 0.4076 - lr: 0.0741\n",
      "Epoch 9/40\n",
      "307/307 [==============================] - 4s 12ms/step - loss: 1.5861 - accuracy: 0.4022 - val_loss: 1.6128 - val_accuracy: 0.4000 - lr: 0.0670\n"
     ]
    }
   ],
   "source": [
    "model = get_model()\n",
    "adam_opt = keras.optimizers.Adam(learning_rate=.01)\n",
    "\n",
    "model.compile(optimizer=adam_opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "lr_scheduler = keras.callbacks.LearningRateScheduler(scheduler(10))\n",
    "early_stopping, model_checkpoint, tensorboard = get_callbacks()\n",
    "history = model.fit(\n",
    "    [X_train, X_train_decoder],\n",
    "    y_train,\n",
    "    epochs=40,\n",
    "    validation_data=([X_valid, X_valid_decoder], y_valid),\n",
    "    callbacks=[early_stopping, model_checkpoint, tensorboard, lr_scheduler])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
